{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6333f9",
   "metadata": {},
   "source": [
    "# Wiki_Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d39cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content)\n",
    "Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "head=Soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"])\n",
    "head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551a7c2",
   "metadata": {},
   "source": [
    "Above code is for finding the header from the wiki main page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d6f81",
   "metadata": {},
   "source": [
    "# IMDM top 100 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5de5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content)\n",
    "Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=Soup.find_all(\"h3\",class_=\"lister-item-header\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992aa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name=[]\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movie_name.append(j.text.replace(\"\\n\",\"\"))\n",
    "movie_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebf2d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#content=BeautifulSoup(req.content,'html.parser')\n",
    "\n",
    "movie_year=[]\n",
    "content=BeautifulSoup(page.content,'html.parser') \n",
    "year=soup.find_all('span',{'class':\"lister-item-year text-muted unbold\"})\n",
    "for i in year:\n",
    "      #for j in i.find_all(\"span\"):\n",
    "        movie_year.append(i.text)\n",
    "movie_year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd15871",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movie_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa471cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating=[]\n",
    "content=BeautifulSoup(page.content,'html.parser')\n",
    "\n",
    "\n",
    "rating=content.find_all(\"div\",class_=\"inline-block ratings-imdb-rating\")\n",
    "for i in rating:\n",
    "        movie_rating.append(i.text)\n",
    "movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating[:]=[ratings.lstrip('\\n') for ratings in movie_rating]\n",
    "movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating[:]=[ratings.rstrip('\\n') for ratings in movie_rating]\n",
    "movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movie_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad198043",
   "metadata": {},
   "source": [
    "now as i have all the data so i am going to make data frame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs[\"Name\"]=movie_name\n",
    "#jobs[\"Year\"]=movie_year\n",
    "jobs[\"Rating\"]=movie_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58274361",
   "metadata": {},
   "source": [
    "here my year code is not working properly i tried. so i am expecting my error reason and solution from your end thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b33e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\Imdb top 100.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ddd4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90d61875",
   "metadata": {},
   "source": [
    "# Top Indian Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39428424",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = req.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "page    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content)\n",
    "Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98257be",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_n=[]\n",
    "mn=Soup.find_all(\"td\",class_=\"titleColumn\")\n",
    "for i in mn:\n",
    "     for j in i.find_all(\"a\"):\n",
    "        movie_n.append(j.text)\n",
    "movie_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_y=[]\n",
    "my=Soup.find_all(\"span\",class_=\"secondaryInfo\")\n",
    "for i in my:\n",
    "        movie_y.append(i.text)\n",
    "movie_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748feaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_r=[]\n",
    "mr=Soup.find_all(\"td\",class_= \"ratingColumn imdbRating\")\n",
    "for i in mr:\n",
    "        movie_r.append(i.text)\n",
    "movie_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fa523",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_r[:]=[mr.lstrip('\\n') for mr in movie_r]\n",
    "movie_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6404b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_r[:]=[mr.rstrip('\\n') for mr in movie_r]\n",
    "movie_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9650ed",
   "metadata": {},
   "source": [
    "now we have all the data to prepare the Data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cbc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "IM=pd.DataFrame({})\n",
    "IM[\"Name\"]=movie_n\n",
    "IM[\"Year\"]=movie_y\n",
    "IM[\"Rating\"]=movie_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\Imdb Indian top Movies.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88308fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e640dbd2",
   "metadata": {},
   "source": [
    "# National_Weather_dataFor_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd10cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1015f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YLhzmPkzYdU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb334ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content, 'html.parser')\n",
    "week=Soup.find(id='seven-day-forecast-body')\n",
    "items=week.find_all(class_='tombstone-container')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bba112",
   "metadata": {},
   "outputs": [],
   "source": [
    "(items[0].find(class_='period-name').get_text())\n",
    "(items[0].find(class_='short-desc').get_text())\n",
    "(items[0].find(class_='temp').get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[item.find(class_='period-name').get_text() for item in items]\n",
    "desc=[item.find(class_='short-desc').get_text() for item in items]\n",
    "Temp=[item.find(class_='temp').get_text() for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data=pd.DataFrame({})\n",
    "weather_data[\"Name\"]=name\n",
    "weather_data[\"Description\"]=desc\n",
    "weather_data[\"Teamprature\"]=Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\weather_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88822f00",
   "metadata": {},
   "source": [
    "# Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a174d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde443a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://bookpage.com/reviews\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d372ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content)\n",
    "Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be60a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=soup.find_all(\"p\",class_=\"sans\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_name=[]\n",
    "for i in (name):\n",
    "    A_name.append(i.text.replace('\\n',''))\n",
    "A_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2bc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_genre=[]\n",
    "\n",
    "genre=soup.find_all(\"p\",class_=\"genre-links hidden-phone\")\n",
    "for i in (genre):\n",
    "    B_genre.append(i.text.replace('\\n',''))\n",
    "B_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ef2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name=[]\n",
    "\n",
    "Book=soup.find_all(\"h4\",class_=\"italic\")\n",
    "for i in (Book):\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Book_name.append(i.text.replace('\\n',''))\n",
    "Book_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef8bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1995d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "Review=[]\n",
    "\n",
    "reviews=soup.find_all(\"p\",class_=\"excerpt\")\n",
    "for i in (reviews):\n",
    "    \n",
    "        Review.append(i.text.replace('\\n',''))\n",
    "Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name\n",
    "A_name\n",
    "B_genre\n",
    "Review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98030ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Book Name']=Book_name\n",
    "df['Author Name']=A_name\n",
    "df['Book genre']=B_genre\n",
    "df['Book Review']=Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19731207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\Book.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d2f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be36d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876e927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d38a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "810ef247",
   "metadata": {},
   "source": [
    "# ODI men Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e608217",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = req.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "page    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content)\n",
    "Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ccca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup=BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82c3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_n=[]\n",
    "team=Soup.find_all(\"span\",class_=\"u-hide-phablet\")\n",
    "for i in team:\n",
    "     \n",
    "        team_n.append(i.text)\n",
    "team_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(team_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "match=[]\n",
    "M=Soup.find_all(\"td\",class_=\"rankings-block__banner--matches\")\n",
    "for i in M:\n",
    "     \n",
    "        match.append(i.text)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfc72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "point=[]\n",
    "p=Soup.find_all(\"td\",class_=\"rankings-block__banner--points\")\n",
    "for i in p:\n",
    "     \n",
    "        point.append(i.text)\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "r=Soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\")\n",
    "for i in r:\n",
    "      rating.append(i.text.strip('\\n'))\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f27c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=Soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")\n",
    "k=[]\n",
    "for i in range(0,len(M),2):\n",
    "        k.append(M[i])\n",
    "for i in k:\n",
    "    match.append(i.get_text())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c997db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=Soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")\n",
    "k=[]\n",
    "for i in range(0,len(M),2):\n",
    "        k.append(M[i])\n",
    "for i in k:\n",
    "    match.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930a901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8628678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37744bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_Men = pd.DataFrame()\n",
    "    ODI_Men['Team_Name'] = team_n\n",
    "    ODI_Men['Matches'] = match\n",
    "    ODI_Men['Ratings'] = point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d22a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ODI_Batsman(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/Batting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febf549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  ##  url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/Batting\"\n",
    "    p5 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5 = BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    p1 = s5.find_all('div', class_='rankings-block__banner--name-large')\n",
    "    Player = []\n",
    "    for i in p1:\n",
    "        Player.append(i.text)\n",
    "    \n",
    "    p2 = s5.find_all('td', class_='table-body__cell rankings-table__name name')\n",
    "    for i in p2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            Player.append(j.text)\n",
    "            \n",
    "    t1 = s5.find(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    Team = []\n",
    "    Team.append(t1.text.strip())\n",
    "    \n",
    "    t2 = s5.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in t2:\n",
    "        Team.append(i.text)\n",
    "        \n",
    "    r1 = s5.find_all('td', class_='table-body__cell rating')\n",
    "    Rating = []\n",
    "    for i in r1:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    ODI_Batsman = pd.DataFrame()\n",
    "    ODI_Batsman['Team'] = Team[0:10]\n",
    "    ODI_Batsman['Player'] = Player[0:10]\n",
    "    ODI_Batsman['Rating'] = Rating[0:10]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*ODI_Batsman.shape))\n",
    "    print(ODI_Batsman.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f3d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd4fe7a2",
   "metadata": {},
   "source": [
    "# ODI_MEN_Batsman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618f9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\"\n",
    "    p5 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5 = BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    p1 = s5.find_all('div', class_='rankings-block__banner--name')\n",
    "    Player = []\n",
    "    for i in p1:\n",
    "        Player.append(i.text)\n",
    "    \n",
    "    p2 = s5.find_all('td', class_='table-body__cell name')\n",
    "    for i in p2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            Player.append(j.text)\n",
    "            \n",
    "    t1 = s5.find(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    Team = []\n",
    "    Team.append(t1.text.strip())\n",
    "    \n",
    "    t2 = s5.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in t2:\n",
    "        Team.append(i.text)\n",
    "        \n",
    "    r1 = s5.find_all('td', class_='table-body__cell u-text-right rating')\n",
    "    Rating = []\n",
    "    for i in r1:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    ODI_Batsman = pd.DataFrame()\n",
    "    ODI_Batsman['Team'] = Team[0:10]\n",
    "    ODI_Batsman['Player'] = Player[0:10]\n",
    "    ODI_Batsman['Rating'] = Rating[0:10]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*ODI_Batsman.shape))\n",
    "    #print(ODI_Batsman.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_Batsman.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\ODI_Batsman.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcd1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0de926f2",
   "metadata": {},
   "source": [
    "# ODI_men_Bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d993d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  url=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/Bowling\"\n",
    "    p5 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5 = BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    p1 = s5.find_all('div', class_='rankings-block__banner--name-large')\n",
    "    Player = []\n",
    "    for i in p1:\n",
    "        Player.append(i.text)\n",
    "    \n",
    "    p2 = s5.find_all('td', class_='table-body__cell rankings-table__name name')\n",
    "    for i in p2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            Player.append(j.text)\n",
    "            \n",
    "    t1 = s5.find(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    Team = []\n",
    "    Team.append(t1.text.strip())\n",
    "    \n",
    "    t2 = s5.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in t2:\n",
    "        Team.append(i.text)\n",
    "        \n",
    "    r1 = s5.find_all('td', class_='table-body__cell rating')\n",
    "    Rating = []\n",
    "    for i in r1:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    ODI_Bowler = pd.DataFrame()\n",
    "    ODI_Bowler['Team'] = Team[0:10]\n",
    "    ODI_Bowler['Player'] = Player[0:10]\n",
    "    ODI_Bowler['Rating'] = Rating[0:10]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*ODI_Bowler.shape))\n",
    "    #print(ODI_Bowler.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc90ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_Bowler.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\ODI_Bowler.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4fa68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e655023",
   "metadata": {},
   "source": [
    "# ODI_Women_Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6fc030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    " url=\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "    p5 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5 = BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    t1 = s5.find_all('span', class_='u-hide-phablet')\n",
    "    Team_Name = []\n",
    "    for i in t1:\n",
    "        Team_Name.append(i.text)\n",
    "        \n",
    "    m1 = s5.find_all('td', class_='rankings-block__banner--matches')\n",
    "    Matches = []\n",
    "    for i in m1:\n",
    "        Matches.append(i.text)\n",
    "        \n",
    "    p1 = s5.find_all('td', class_='rankings-block__banner--points')\n",
    "    Point = []\n",
    "    for i in p1:\n",
    "        Point.append(i.text) \n",
    "    \n",
    "    r1 = s5.find_all('td', class_='rankings-block__banner--rating u-text-right')\n",
    "    Rating = []\n",
    "    for i in r1:\n",
    "        Rating.append(i.text.strip('\\n'))\n",
    "    Ratings = [] \n",
    "    Ratings.append(Rating[0].strip())\n",
    "    \n",
    "    m1 = s5.find_all('td', class_='table-body__cell u-center-text')\n",
    "    k = []\n",
    "    for i in range(0,len(m1),2):\n",
    "        k.append(m1[i])\n",
    "    for i in k:\n",
    "        Matches.append(i.get_text())\n",
    "        \n",
    "    k = []\n",
    "    for i in range(1,len(m1),2):\n",
    "        k.append(m1[i])\n",
    "    for i in k:\n",
    "        Point.append(i.get_text())\n",
    "        \n",
    "    r1 = s5.find_all('td', class_='table-body__cell u-text-right rating')\n",
    "    for i in r1:\n",
    "        Ratings.append(i.get_text().strip('\\n'))\n",
    "        \n",
    "    ODI_Women = pd.DataFrame()\n",
    "    ODI_Women['Team_Name'] = Team_Name[0:10]\n",
    "    ODI_Women['Matches'] = Matches[0:10]\n",
    "    ODI_Women['Ratings'] = Ratings[0:10]\n",
    "    ODI_Women['Point'] = Point[0:10]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*ODI_Women.shape))\n",
    "    #print(ODI_Women.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ba3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_Women.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\ODI_Women.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e35dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "841302b1",
   "metadata": {},
   "source": [
    "# ODI_Women_Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39b55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed416441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70020724",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "    p5 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5 = BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    p1 = s5.find_all('div', class_='rankings-block__banner--name-large')\n",
    "    Player = []\n",
    "    for i in p1:\n",
    "        Player.append(i.text)\n",
    "    \n",
    "    p2 = s5.find_all('td', class_='table-body__cell rankings-table__name name')\n",
    "    for i in p2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            Player.append(j.text)\n",
    "            \n",
    "    t1 = s5.find(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    Team = []\n",
    "    Team.append(t1.text.strip())\n",
    "    \n",
    "    t2 = s5.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in t2:\n",
    "        Team.append(i.text)\n",
    "        \n",
    "    r1 = s5.find_all('td', class_='table-body__cell rating')\n",
    "    Rating = []\n",
    "    for i in r1:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    ODI_Woman = pd.DataFrame()\n",
    "    ODI_Woman['Team'] = Team[0:10]\n",
    "    ODI_Woman['Player'] = Player[0:10]\n",
    "    ODI_Woman['Rating'] = Rating[0:10]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*ODI_Woman.shape))\n",
    "    #print(ODI_Woman.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_Woman.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\ODI_WomanPlayer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d88258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9daf94d1",
   "metadata": {},
   "source": [
    "# ODI_Allrounder_Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdceb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    " url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "    p5 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5 = BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    p1 = s5.find_all('div', class_='rankings-block__banner--name-large')\n",
    "    Player = []\n",
    "    for i in p1:\n",
    "        Player.append(i.text)\n",
    "    \n",
    "    p2 = s5.find_all('td', class_='table-body__cell rankings-table__name name')\n",
    "    for i in p2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            Player.append(j.text)\n",
    "            \n",
    "    t1 = s5.find(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    Team = []\n",
    "    Team.append(t1.text.strip())\n",
    "    \n",
    "    t2 = s5.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in t2:\n",
    "        Team.append(i.text)\n",
    "        \n",
    "    r1 = s5.find_all('td', class_='table-body__cell rating')\n",
    "    Rating = []\n",
    "    for i in r1:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    ODI_Allrounder = pd.DataFrame()\n",
    "    ODI_Allrounder['Team'] = Team[0:10]\n",
    "    ODI_Allrounder['Player'] = Player[0:10]\n",
    "    ODI_Allrounder['Rating'] = Rating[0:10]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*ODI_Allrounder.shape))\n",
    "    #print(ODI_Allrounder.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_Allrounder.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\ODI_AllrounderW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7af0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a439f5d",
   "metadata": {},
   "source": [
    "# Amazon_Data_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb5f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bba1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = requests.get(\"https://www.amazon.in/s?k=mobile&rh=p_36%3A-20000000&qid=1621975129&rnid=1318502031&ref=sr_nr_p_36_5\")\n",
    "u.status_code\n",
    " url=\"https://www.amazon.in/s?k=mobile&rh=p_36%3A-20000000&qid=1621975129&rnid=1318502031&ref=sr_nr_p_36_5\"\n",
    "    p7 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p7.status_code)\n",
    "    \n",
    "    s7 = BeautifulSoup(p7.content, 'html.parser')\n",
    "    #print(s7.prettify())\n",
    "    \n",
    "    m_name = s7.find_all('span', class_='a-size-medium a-color-base a-text-normal')\n",
    "    m_price = s7.find_all('span', class_='a-price-whole')\n",
    "    m_rating = s7.find_all('span', class_=\"a-icon-alt\")\n",
    "    m_img = s7.find_all('img', class_=\"s-image\")\n",
    "    \n",
    "    Mobile = []\n",
    "    for i in m_name:\n",
    "        Mobile.append(i.get_text())\n",
    "        \n",
    "    Price = []\n",
    "    for i in m_price:\n",
    "        Price.append(i.get_text())\n",
    "        \n",
    "    Rating = []\n",
    "    for i in m_rating:\n",
    "        Rating.append(i.get_text())\n",
    "        \n",
    "    Image = []\n",
    "    for i in m_img:\n",
    "        Image.append(i.get('srcset'))\n",
    "        \n",
    "    Mobile_dataset = pd.DataFrame()\n",
    "    Mobile_dataset['Mobile_Name'] = Mobile[0:16]\n",
    "    Mobile_dataset['Mobile_Price'] = Price[0:16]\n",
    "    Mobile_dataset['Mobile_rating'] = Rating[0:16]\n",
    "    Mobile_dataset['Image_Link'] = Image[0:16]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*Mobile_dataset.shape))\n",
    "    print(Mobile_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mobile_dataset.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\AmazonMobieData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47e0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c63164f0",
   "metadata": {},
   "source": [
    "# Intershala_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40910a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84290cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://internshala.com/fresher-jobs\"\n",
    "    p9 = requests.get(url)\n",
    "    #p9.content\n",
    "    print(p9.status_code)\n",
    "    \n",
    "    s9 = BeautifulSoup(p9.content, \"html.parser\")\n",
    "    #print(s9.prettify())\n",
    "    \n",
    "    title = []\n",
    "    company = []\n",
    "    ctc = []\n",
    "    apply_date = []\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    get_titles = s9.find_all('div',class_ = \"heading_4_5 profile\")   \n",
    "    get_companies = s9.find_all('a', class_ = 'link_display_like_text')\n",
    "    get_ctcadate = s9.find_all('div',class_ = \"item_body\", id = False)\n",
    "    \n",
    "    for cdate in get_ctcadate:\n",
    "        temp.append(cdate.text.strip())\n",
    "        \n",
    "    for t, c in zip(get_titles, get_companies):\n",
    "        title.append(t.text.strip())\n",
    "        company.append(c.text.strip())\n",
    "    \n",
    "    for i in temp:\n",
    "        ctc.append(i) if 'LPA' in i else apply_date.append(i)\n",
    "            \n",
    "    Internshala = pd.DataFrame({'Title': title,\n",
    "                     'Company': company,\n",
    "                     'CTC': ctc,\n",
    "                     'Apply Date': apply_date\n",
    "                     })\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*Internshala.shape))\n",
    "    #print(Internshala.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Internshala.to_csv(r'C:\\Users\\Administrator\\Desktop\\Gitu\\Internshala.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae450a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
